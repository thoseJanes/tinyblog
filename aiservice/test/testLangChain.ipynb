{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.stdout import StdOutCallbackHandler\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools, AgentExecutor\n",
    "from langchain.tools import tool\n",
    "from langchain.tools import StructuredTool\n",
    "import os\n",
    "import yaml\n",
    "from typing import List\n",
    "def createDir(path:str) -> bool:\n",
    "    \"\"\"在指定的path下创建一个目录。\n",
    "    每次只能创建一个层级的新目录。\n",
    "    返回值表示是否成功\"\"\"\n",
    "    os.mkdir(path)\n",
    "    return True\n",
    "\n",
    "# ChatOpenAI、agent、链等，本身是线程安全的，但是如果附带记忆机制，或含跨线程callbacks，则不是线程安全的。\n",
    "class AgentPool:\n",
    "    def __init__(self, pool_size):\n",
    "        tools = load_tools([\"ddg-search\"], llm=llm)\n",
    "        tools.append(StructuredTool.from_function(\n",
    "            createDir,\n",
    "            name=\"创建目录\",\n",
    "            description=\"\"\"在指定的path下创建一个目录。\n",
    "            每次只能创建一个层级的新目录。返回值表示是否成功。执行该工具时需要等待一秒才能返回结果\"\"\"\n",
    "        ))\n",
    "        self.agents:List[AgentExecutor] = []\n",
    "        self.loadConfig()\n",
    "        for i in range(pool_size):\n",
    "            llm = ChatOpenAI(\n",
    "                model= self.llm_config['model'],\n",
    "                openai_api_key= self.llm_config['api-key'],  # 替换为你的SiliconFlow API Key\n",
    "                base_url= self.llm_config['url'],  # SiliconFlow的API地址\n",
    "                streaming=True,  # 启用流式输出\n",
    "                # callbacks=[FormattedStreamingCallback()],\n",
    "                model_kwargs={\"chunk_size\":50}\n",
    "            )\n",
    "            agent = initialize_agent(\n",
    "                tools,\n",
    "                llm,\n",
    "                agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,  # 专为 Chat 模型优化的 Agent\n",
    "                handle_parsing_errors=True,\n",
    "                verbose=True\n",
    "            )\n",
    "            self.agents.append(agent)\n",
    "\n",
    "    def loadConfig(self):\n",
    "        config_path = os.path.join(os.path.curdir, \"..\", \"configs\", \"aiservice.yaml\")\n",
    "        with open(config_path, encoding=\"UTF-8\") as config_file:\n",
    "            config = yaml.load(config_file, yaml.FullLoader)\n",
    "        self.llm_config = config['llm']\n",
    "    def run(self):\n",
    "        agent = self.agents[0]\n",
    "        response = agent.run(\"\"\"\n",
    "        在当前目录下逐步创建3个层级的嵌套目录，且每个目录的名字随机生成。\n",
    "        \"\"\")\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough, RunnableBranch\n",
    "from langchain.chains import SequentialChain, ConversationChain, LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "template_1 = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"解析问题：{question}\"\n",
    ")\n",
    "\n",
    "template_2 = PromptTemplate(\n",
    "    input_variables=[\"answer\"],\n",
    "    template=\"你是一个有多年教学经验的大学教师，根据该答案：{answer}，扩展更多知识点以形成系统化知识，不要重复原答案内容，使用颜文字修饰语言。\"\n",
    ")\n",
    "\n",
    "class EventCallback(StdOutCallbackHandler):\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        pass\n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        pass\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 存储对话的变量名\n",
    "    return_messages=True       # 设置为True时返回消息列表（适合ChatModels）\n",
    ")\n",
    "\n",
    "chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"answer\": RunnablePassthrough()\n",
    "} | RunnableBranch(\n",
    "    (lambda x: \"t\" in x[\"question\"], template_1),\n",
    "    (lambda x: \"t\" not in x[\"question\"], template_2),\n",
    "    template_2\n",
    ")\n",
    "chain = chain.with_config(callbacks=[EventCallback()], memory=memory)\n",
    "\n",
    "\n",
    "output = chain.invoke(\"es\")\n",
    "output = chain.invoke(\"efads\")\n",
    "output = chain.invoke(\"efsdads\")\n",
    "\n",
    "print(output)\n",
    "# print(chain..load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableSequence, RunnablePassthrough\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "\n",
    "\n",
    "template_1 = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"你是一个LCEL的熟练使用者，解析问题：{question}\"\n",
    ")\n",
    "\n",
    "template_2 = PromptTemplate(\n",
    "    input_variables=[\"ans\"],\n",
    "    template=\"你是一个有多年教学经验的大学教师，熟悉LCEL，根据该答案：{answer}，扩展更多知识点以形成系统化知识，不要重复原答案内容，使用颜文字修饰语言。\"\n",
    ")\n",
    "\n",
    "#rm = RunnableWithMessageHistory(get_session_history=)\n",
    "\n",
    "chain = RunnableSequence(\n",
    "    first=template_1 | llm,\n",
    "    last=template_2 | llm\n",
    ")\n",
    "\n",
    "# chain = (\n",
    "#     {\"question\": RunnablePassthrough()}\n",
    "#     | template_1\n",
    "#     | llm  # 调用SiliconFlow模型\n",
    "#     | template_2\n",
    "#     | llm  # 可多次调用\n",
    "# )\n",
    "\n",
    "resp = chain.invoke({\"question\": \n",
    "\"\"\"\n",
    "什么是OutputParser？什么是PydanticOutputParser？如何使用？\n",
    "\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "model_name = \"all-MiniLM-L6-v2\"  # 轻量级模型，适用于CPU\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# 创建嵌入模型\n",
    "db = FAISS.from_documents(documents, embeddings)\n",
    "# 进行相似性搜索\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
