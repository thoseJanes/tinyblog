{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server started, listening on port 50051\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "import grpc\n",
    "import pkg.proto.aiservice.v1.aiservice_pb2_grpc as pb \n",
    "from pkg.proto.aiservice.v1.aiservice_pb2 import PromptContentRequest, GenerateTitleAndTagResponse, PromptRequest, PolishContentResponse, SearchPostsResponse\n",
    "from internal.aiserver.chain.generateTitleAndTag import GenerateTitleAndTagChain, GenerateTitleAndTagOutput\n",
    "from internal.aiserver.chain.polishContent import PolishContentChain, PolishContentModel\n",
    "from internal.aiserver.chain.searchPosts import SearchPostsChain, SearchPostsModel\n",
    "\n",
    "import asyncio\n",
    "\n",
    "class AIService(pb.AIService):\n",
    "    async def generateTitleAndTag(self, request:PromptContentRequest, context:grpc.ServicerContext):\n",
    "        print(\"generateTitleAndTag requested\")\n",
    "        resp:GenerateTitleAndTagOutput = await GenerateTitleAndTagChain.ainvoke(request.prompt, request.content)\n",
    "        return GenerateTitleAndTagResponse(title=resp.title, tags=resp.tags)\n",
    "    async def polishContent(self, request:PromptContentRequest, context:grpc.ServicerContext):\n",
    "        print(\"polishContent requested\")\n",
    "        async for chunk in PolishContentChain.astream(request.prompt, request.content):\n",
    "            yield PolishContentResponse(contentChunk=chunk)\n",
    "    async def searchPosts(self, request:PromptRequest, context:grpc.ServicerContext):\n",
    "        print(\"searchPosts requested\")\n",
    "        messages = await SearchPostsChain.ainvoke(request.prompt)\n",
    "        result:str = messages[\"messages\"][-1].content\n",
    "        try:\n",
    "            slices = result.split(\">\")\n",
    "            evaluation = slices[0][1:]\n",
    "            id_list = slices[1].split(\",\")\n",
    "            return SearchPostsResponse(evaluation=evaluation, ids=id_list)\n",
    "        except:\n",
    "            return SearchPostsResponse(evaluation=\"查找失败！最终信息：{result}\", ids=[])\n",
    "async def serve():\n",
    "    #service中的方法需要是线程安全的。\n",
    "    server = grpc.aio.server(futures.ThreadPoolExecutor(max_workers=10))\n",
    "    pb.add_AIServiceServicer_to_server(AIService(), server)\n",
    "    server.add_insecure_port('[::]:50051')\n",
    "    await server.start()\n",
    "    print(\"Server started, listening on port 50051\")\n",
    "    await server.wait_for_termination()\n",
    "\n",
    "import nest_asyncio  # pip install nest_asyncio\n",
    "nest_asyncio.apply()  # 允许嵌套事件循环\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    await serve()\n",
    "    # asyncio.run(serve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
