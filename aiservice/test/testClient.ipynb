{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title ids: \"21\"\n",
      "ids: \"20\"\n",
      "ids: \"18\"\n",
      "ids: \"17\"\n",
      "ids: \"16\"\n",
      "ids: \"15\"\n",
      "ids: \"14\"\n",
      "ids: \"13\"\n",
      "ids: \"10\"\n",
      "ids: \"3\"\n",
      "ids: \"2\"\n",
      "ids: \"1\"\n",
      "evaluation: \"我查找了这些博客的标题，但未找到明显描述令人震惊的内容，可能需要进一步搜索内容字段\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "from pkg.proto.aiservice.v1.aiservice_pb2 import GenerateTitleAndTagResponse, PromptContentRequest, PolishContentResponse, PromptRequest, SearchPostsResponse\n",
    "import pkg.proto.aiservice.v1.aiservice_pb2_grpc as pb\n",
    "from internal.aiserver.chain.searchPosts import SearchPostsChain, SearchPostsModel\n",
    "import nest_asyncio  # pip install nest_asyncio\n",
    "import asyncio\n",
    "import langchain\n",
    "\n",
    "nest_asyncio.apply()  # 允许嵌套事件循环\n",
    "async def generateTitleAndTagTest():\n",
    "    async for response in stub.polishContent(PromptContentRequest(\n",
    "            prompt=\"博客风格要求生动活泼。\",\n",
    "            content=\"发达随父ijeasnvlanlreerlb4534哪控件那律哪里就可1\"\n",
    "        )):\n",
    "        print(\"response:\\n\", response)\n",
    "\n",
    "async def polishContentTest():\n",
    "    async for response in stub.polishContent(PromptContentRequest(\n",
    "            prompt=\"博客风格要求生动活泼。\",\n",
    "            content=\"发达随父ijeasnvlanlreerlb4534哪控件那律哪里就可1\"\n",
    "        )):\n",
    "        print(\"response:\\n\", response.contentChunk)\n",
    "\n",
    "async def searchPostsTest():\n",
    "    response = await stub.searchPosts(PromptRequest(\n",
    "            prompt=\"给我最让人震惊的一篇博客。\",\n",
    "        ))\n",
    "    print(\"response:\\n\", response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    channel = grpc.aio.insecure_channel(\"localhost:50051\")\n",
    "    stub:pb.AIServiceStub = pb.AIServiceStub(channel)\n",
    "\n",
    "    asyncio.run(searchPostsTest())\n",
    "    # response:PolishContentResponse = stub.polishContent(\n",
    "    #     PromptContentRequest(\n",
    "    #         prompt=\"博客风格要求生动活泼。\",\n",
    "    #         content=\"博客内容\"\n",
    "    #     )\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "\n",
    "messages = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "{\n",
    "    \"input\": query,\n",
    "    \"output\": messages[\"messages\"][-1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='0fda1c3c-f7b7-45bf-b4be-81848fd41f0d')]}\n",
      "Hello! How can I assist you today?\u001b[1m[updates]\u001b[0m {'agent': {'messages': [AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-ai/DeepSeek-V3'}, id='run--972fccf7-312e-4294-8676-9fc64daaaaf7-0', usage_metadata={'input_tokens': 836, 'output_tokens': 54, 'total_tokens': 890, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='0fda1c3c-f7b7-45bf-b4be-81848fd41f0d'), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-ai/DeepSeek-V3'}, id='run--972fccf7-312e-4294-8676-9fc64daaaaf7-0', usage_metadata={'input_tokens': 836, 'output_tokens': 54, 'total_tokens': 890, 'input_token_details': {}, 'output_token_details': {}})]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='0fda1c3c-f7b7-45bf-b4be-81848fd41f0d'),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-ai/DeepSeek-V3'}, id='run--972fccf7-312e-4294-8676-9fc64daaaaf7-0', usage_metadata={'input_tokens': 836, 'output_tokens': 54, 'total_tokens': 890, 'input_token_details': {}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.callbacks.stdout import StdOutCallbackHandler\n",
    "# from langchain.agents import AgentType, initialize_agent, load_tools, AgentExecutor, create_react_agent\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.tools import tool\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough, RunnableBranch\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import field_validator, BaseModel, Field\n",
    "from typing import Dict, List, Any\n",
    "from internal.pkg.runnable.llm import GetLanguageModel\n",
    "\n",
    "def query():\n",
    "    return \"hello\"\n",
    "tools = []\n",
    "tools.append(StructuredTool.from_function(\n",
    "            func=query,\n",
    "            name=\"查询数据库\",\n",
    "            description=\"输入查询语句（注意加分号），输出字符串作为结果\"\n",
    "        ))\n",
    "agent = create_react_agent(\n",
    "            GetLanguageModel(streaming=True),\n",
    "            tools,\n",
    "            debug=True,\n",
    "        )\n",
    "\n",
    "template = PromptTemplate(\n",
    "            input_variables=[\"prompt\", \"memory\"],\n",
    "            template=\"\"\"你是一个搜索助手，你需要根据用户的描述在数据库中搜索相关博客，返回相关博客的Id，并给出一个简要的搜索结果与用户需求贴合程度的分析。\n",
    "            存储博客的数据库名称为post_table，其中包含title, content, postId, Id, updatedAt, createdAt等字段。\n",
    "            注意，你只拥有数据库中表post_table的select权限，且每次搜索时必须限制搜索结果的数量最大为100，\n",
    "            如非必要，不要搜索content字段，防止占用太多数据库资源。\n",
    "            \n",
    "            你可以进行多轮迭代使用工具来解决问题，当你决定继续获取信息时，在输出开头使用<continue>;当你决定输出结果给用户时，在输出开头使用<output>。在4轮迭代内需要返回最终结果。\n",
    "            输出的格式为：<output><贴合程度分析>postid:postid:postid...\\n\n",
    "            输出的示例为：\n",
    "            <example>\n",
    "            输入：给我最让人震惊的一篇博客。\n",
    "            输出：<output><你要求找到最能让你震惊的博客，但是没有说出哪类博客最能让你震惊，以下结果是一般而言能让人震惊的博客>34:43:56:88:204\n",
    "            </example>\n",
    "            用户的要求是：<request>{request}</request>\\n\n",
    "            当前操作的历史是：<memory>{memory}</memory>\n",
    "            \"\"\",\n",
    "        )\n",
    "agent.invoke({\"messages\": {\"role\":\"system\", \"content\":template.invoke({\"request\":})}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
